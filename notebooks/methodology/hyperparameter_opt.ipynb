{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b876f314",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crypto_thesis.data_domains.modeling import logreg_model_fit, xgboost_model_fit\n",
    "from crypto_thesis.data_domains.modeling.lstm import _build_lstm_timestamps_seq\n",
    "from pprint import pprint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81902b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "\n",
    "import pandas as pd\n",
    "from keras.engine.sequential import Sequential\n",
    "from keras.layers import LSTM, BatchNormalization, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from crypto_thesis.utils import optimize_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c59ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440db2ef",
   "metadata": {},
   "source": [
    "## Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed6921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = [\"label\"]\n",
    "INDEX_COL = \"window_nbr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee0797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_train_multic = catalog.load(\"master_table_train_multic\")\n",
    "mt_train_nonmultic = catalog.load(\"master_table_train_nonmultic\")\n",
    "\n",
    "seq_length = catalog.load(\"params:lstm_timestamp_seq_length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1981ae",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9186ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xgboost_param_combinations():\n",
    "    return {\n",
    "    'eval_metric': ['auc'],\n",
    "     'n_estimators': [300, 500, 1000],\n",
    "     'max_depth': [3, 5],\n",
    "     'reg_lambda': [0.05, 0.01, 0.1],\n",
    "     'gamma': [0.01],\n",
    "     'min_child_weight': [2.0],\n",
    "     'learning_rate': [0.01, 0.05, 0.1],\n",
    "     'objective': ['binary:logistic'],\n",
    "     'sampling_method': ['uniform'],\n",
    "     'tree_method': ['auto']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6452027",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_def_params = catalog.load(\"params:xgboost_default_params\")\n",
    "xgb_model_params = build_xgboost_param_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26480773",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, df_params_opt = xgboost_model_fit(master_table_train=mt_train_multic,\n",
    "                        model_params=xgb_model_params, \n",
    "                        xgboost_optimize_params=True, \n",
    "                        xgboost_default_params=xgb_def_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde22da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(df_params_opt.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7dfc6",
   "metadata": {},
   "source": [
    "## LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b53475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_logreg_param_combinations():\n",
    "    return {\n",
    "      \"solver\": [\"saga\"],\n",
    "      \"penalty\": [\"elasticnet\"],\n",
    "      \"tol\": [0.0001, 0.001, 0.01],\n",
    "      \"C\": [0.01, 0.1, 1.0],\n",
    "      \"max_iter\": [100, 200],\n",
    "      \"fit_intercept\": [True],\n",
    "      \"class_weight\": [\"balanced\"],\n",
    "      \"l1_ratio\": [0.01, 0.1, 1.0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_def_params = catalog.load(\"params:logreg_default_params\")\n",
    "logreg_model_params = build_logreg_param_combinations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161cfb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, df_params_opt = logreg_model_fit(master_table_train=mt_train_nonmultic,\n",
    "                                    model_params=logreg_model_params, \n",
    "                                    logreg_optimize_params=True, \n",
    "                                    logreg_default_params=logreg_def_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(df_params_opt.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ddd60c",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f26b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_param_combinations():\n",
    "    return {\n",
    "      # \"batch_size\": [10, 20, 40, 60, 80, 100],\n",
    "      \"batch_size\": [1000],\n",
    "      # \"epochs\": [10, 50, 100],\n",
    "      \"epochs\": [100],\n",
    "      # \"optimizer\": ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam'],\n",
    "      \"model__optimizer\": ['SGD'],\n",
    "      # \"optimizer__learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "      # \"optimizer__learning_rate\": [0.01],\n",
    "      # \"optimizer__momentum\": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "      # \"optimizer__momentum\": [0.2],\n",
    "      # \"init_mode\": ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform'],\n",
    "      # \"init_mode\": ['uniform']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde0698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_lstm_model(X_train_scaled_seq: pd.DataFrame,\n",
    "                       seq_length: int,\n",
    "                       optimizer: str = \"adam\") -> Sequential:\n",
    "\n",
    "    # parameters\n",
    "    LAYERS = [20, 20, 20, 1] #[10, 10, 10, 1]                # number of units in hidden and output layers\n",
    "    N = X_train_scaled_seq.shape[2]                 # number of features\n",
    "    LR = 0.0005 #0.0005                            # learning rate of the gradient descent\n",
    "    LAMBD = 0.005 #0.001                         # lambda in L2 regularizaion\n",
    "    DP = 0.0 #0.0                             # dropout rate\n",
    "    RDP = 0.0 #0.0                            # recurrent dropout rate\n",
    "\n",
    "    # model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(\n",
    "        input_shape=(seq_length, N),\n",
    "        units=LAYERS[0],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        kernel_regularizer=l2(LAMBD),\n",
    "        recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=True,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        unroll=False\n",
    "                ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(\n",
    "        units=LAYERS[1],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        kernel_regularizer=l2(LAMBD),\n",
    "        recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=True,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        unroll=False\n",
    "                ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LSTM(\n",
    "        units=LAYERS[2],\n",
    "        activation='tanh',\n",
    "        recurrent_activation='hard_sigmoid',\n",
    "        kernel_regularizer=l2(LAMBD),\n",
    "        recurrent_regularizer=l2(LAMBD),\n",
    "        dropout=DP,\n",
    "        recurrent_dropout=RDP,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        stateful=False,\n",
    "        unroll=False\n",
    "                ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(\n",
    "        units=LAYERS[3],\n",
    "        activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with Adam optimizer\n",
    "    # model.compile(\n",
    "    #     loss='binary_crossentropy',\n",
    "    #     metrics=['accuracy'],\n",
    "    #     optimizer=Adam(lr=LR))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aa964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set numpy seed\n",
    "np.random.seed(0)\n",
    "# set tensorflow seed\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "tf.keras.utils.disable_interactive_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b057b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table_train = mt_train_multic.set_index(INDEX_COL)\n",
    "X_train, y_train = master_table_train.drop(columns=TARGET_COL), master_table_train[TARGET_COL]\n",
    "\n",
    "X_train_scaled_seq, y_train_scaled_seq = _build_lstm_timestamps_seq(X=X_train,\n",
    "                                                                    y=y_train,\n",
    "                                                                    seq_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model_params = build_lstm_param_combinations()\n",
    "keras_model = _create_lstm_model(X_train_scaled_seq=X_train_scaled_seq, seq_length=seq_length)\n",
    "\n",
    "model = KerasClassifier(model=keras_model,\n",
    "                        loss=\"binary_crossentropy\",\n",
    "                        verbose=0)\n",
    "\n",
    "pprint(lstm_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef6e4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_opt = optimize_params(model=model,\n",
    "                grid=lstm_model_params,\n",
    "                X_train=X_train_scaled_seq,\n",
    "                y_train=y_train_scaled_seq,\n",
    "                n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7be8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(params_opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57295601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (crypto_thesis)",
   "language": "python",
   "name": "kedro_crypto_thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
